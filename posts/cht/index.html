<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@100;300;400;500;700;900&family=Rubik:ital,wght@0,400;0,500;0,600;0,700;1,300;1,400;1,500;1,600;1,700&&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css integrity=sha384-B0vP5xmATw1+K9KRQjQERJvTumQW0nPEzvF6L/Z6nronJ3oUOFUFpCjEUQouq2+l crossorigin=anonymous><link rel=stylesheet type=text/css href=/css/style.css><title>CHT 致科技人 ｜ Esther's Life</title><meta name=description content="esther 看完 The Social Dilemma 之後訪問了 Center for Humane Technology 的網站，然後讀到這篇讓我很有感觸的文章。因為工作的關係，對科技其實很熟悉也更加理解科技的問題，希望大家都能意識到這些問題，也希望未來法律或是教育能追上科技的發展。
CHT 也有提供找回掌控權的相關建議，可以參考Take Control
 原文 Center for Humane Technology: For Technologists https://www.humanetech.com/technologists"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','G-ZS1GBZ1JP6','auto');ga('send','pageview');}</script><link rel="shortcut icon" href=/images/favicon.ico></head><body><header><div><a href=/ class=logo><img width=160px src=/img/esther.png></a></div><div><nav id=nav class="nav justify-content-end"><a class=nav-link title=Esther href=/esther/ target=_self><i data-feather=message-circle></i></a><a class=nav-link title=Blog href=/posts/ target=_self><i data-feather=book-open></i></a><a class=nav-link title=Portfolio href=/portfolio/ target=_self><i data-feather=briefcase></i></a><a class=nav-link title=Playground href=/playground/ target=_self><i data-feather=box></i></a><a class=nav-link title=Github href=https://github.com/estherj-hsu target=_blank><i data-feather=github></i></a><a class=nav-link title=LinkedIn href=https://www.linkedin.com/in/estherjhsu/ target=_blank><i data-feather=linkedin></i></a></nav></div></header><main><h1 class=text-center>CHT 致科技人</h1><div class="text-center mt-4 mb-5"><div class=meta><i width=14px height=14px data-feather=calendar></i><time datetime=2020-10-08>Oct 8, 2020</time>
<span class=mx-3></span><i width=14px height=14px data-feather=tag></i><a class=tag href=/tags/translation>Translation</a>
<a class=tag href=/tags/others>Others</a></div></div><h3 id=esther>esther</h3><p>看完 <a href=https://www.netflix.com/tw/title/81254224 target=_blank>The Social Dilemma</a> 之後訪問了 Center for Humane Technology 的網站，然後讀到這篇讓我很有感觸的文章。因為工作的關係，對科技其實很熟悉也更加理解科技的問題，希望大家都能意識到這些問題，也希望未來法律或是教育能追上科技的發展。<br>CHT 也有提供找回掌控權的相關建議，可以參考<a href=https://www.humanetech.com/take-control target=_blank>Take Control</a></p><blockquote><p>原文 Center for Humane Technology: For Technologists
<a href=https://www.humanetech.com/technologists target=_blank>https://www.humanetech.com/technologists</a></p></blockquote><hr><h2 id=致科技人>致科技人</h2><h3 id=我們可以一起改變科技的建構方式>我們可以一起改變科技的建構方式</h3><h3 id=我們在做什麼>我們在做什麼</h3><p>我們直接與科技人合作，為成功創造新的定義：尊重人性，有責任地成長並幫助我們以我們最深刻的價值觀生活。</p><h3 id=人道科技準則>人道科技準則</h3><h4 id=深入之前>深入之前</h4><p>深入這些準則之前，了解這些內容如何驅動我們的工作是會有幫助的。科技文化需要升級。進入一個所有科技都以人為主的世界，我們需要以如何為人類生活增價有更深層的了解來取代我們對科技舊有的假設。</p><ul><li><p><strong>科技永遠不會中立</strong><br><em>我們正在建構一個社交社會</em><br>有些科技人相信科技是中立的。但事實上，它從來不是，也永遠不會是，有兩個原因：第一，我們的價值與假設是奠基在我們建立的環境中。每當你將內容或是介面選項放在用戶前，你都是在影響他們；不管那是預設值、由顯示的內容和順序選擇的或是建議選項。由於不可能將所有的選項以相同的優先順序呈現，因此你所選擇的就是強調你價值觀的結果。<br>第二，不論是人或產品，人與人或是人與科技之間每一次的互動都會改變彼此。即使是一支看起來中立的鐵鎚，也會讓我們的手臂在使用時變強壯。就像是現實社會中的建築和都市規劃影響人們的感受與互動，數位科技會形塑我們的線上形象。例如，社交媒體中的讚、回覆和分享影響著我們選擇的發文的內容，而他人內容的反饋則改變我們對發文本身的感受。<br>中立是一種神話。<br>人類當前和未來的危機掌控在你的手上！</p></li><li><p><strong>從人類的弱點來看</strong><br><em>人腦天生就很脆弱</em><br>在我們看見科技的價值時，我們必須考慮到人腦的脆弱性。已經有許多書提到<a href=https://zh.wikipedia.org/wiki/認知偏誤列表 target=_blank>認知偏誤</a>的進化，而我們傾向高估我們的代理偏見。為快速了解這點，請想想你上一次觀看超出原本預期外Youtube影片的情況。Youtube的推薦演算法非常擅長找出能讓你繼續觀看的內容，它並不關心你生命中的其他計畫，更不用說幫助你實現你的目標。<br>由於我們的許多認知偏誤，像是觀看時間或點擊次數之類的簡單互動指標，通常無法揭露使用者的真實意圖。當你忽略這些偏見或是透過利用其優化參與度時，就會出現一系列的危害。<br><a href=https://zh.wikipedia.org/wiki/確認偏誤 target=_blank>確認偏誤</a>讓我們對支持我們觀點的內容更加參與，導致同溫層（Filter bubbles）和假新聞氾濫。當前的偏見會優先考慮短期效益，這使我們在陳受壓力時將暴飲暴食當做自我治療的方法，而非解決壓力的根源。對社會認同的渴望驅使我們採取我們在網路群組上看到的有害行為，即使我們通常不會這樣做。<br>積極的優化參與度指標就像讓你失去掌控權一樣。它讓使用者那舊石器時代，易受攻擊的大腦，負責決定什麼是對你產品有價值的。這種方法結合最新的機器學習和A/B測試，導致大規模的一系列危害出現，我們稱之為<a href=https://www.humanetech.com/what-we-do#problem target=_blank>人類降級</a>。</p></li><li><p><strong>轉變產品文化</strong><br><em>文化變革是必要且艱難的</em><br>我們的願景是用一種會產生人道科技的新思維來取代當前在塑造產品開發文化時的有害假設。集成這種新範例意味著產品組織內外的過程改變、時間與精力。
我們意識到有許多對立的力量，系統性的文化變革絕非易事。若你有關於如何推動這一變化的想法，或者你認為可以滿足CHT的特定要求，請你聯繫我們。</p></li><li><p><strong>為人道科技創造市場條件</strong><br><em>這種範例轉換需要會獎勵人道科技的市場</em><br>CHT和許多其他組織正在透過媒體、父母、孩子、法規、投資人、股東、像你依樣的科技人等的壓力一起創造這樣的環境。<br>想了解更多，請閱讀<a href=https://www.humanetech.com/what-we-do/#work target=_blank>關於我們</a>。</p></li></ul><h4 id=準則>準則</h4><p>這種新的範例適用於那些認同科技正在逐漸塑造我們的社會結構，且希望能運用其特殊技能來使科技與人性重新結合的科技人。</p><ul><li><p><strong>著重於價值</strong><br><em>而非執迷於參與度指標</em><br>當你沈迷於參與度指標時，你會掉入一個陷阱：假設自己在給使用者他們想要的，但實際上你是在掠奪他們的<a href=https://www.visualcapitalist.com/every-single-cognitive-bias/ target=_blank>固有弱點</a>。即使我們知道自己應該做其他事情，但那些聳動的標題也驅使我們點下它。看到某人比我們有更多的追蹤人數會使我們感到自卑。知道朋友們聚會撇開我們會讓我們感到被排擠。而且，一但我們相信了錯誤的訊息就很難被替換。<br>取而代之的是，你可以被<strong>價值驅使</strong>的同時仍然獲得指標資訊。你可以花時間思考要使用產品或功能去創建特定的價值（例如：健康、福利、聯繫、生產力、娛樂、創造力&mldr;）。這些價值觀可以成為靈感和優先次序的來源。你可以藉由投資你認為有價值的複雜性相匹配的理解機制來直接衡量你的成功，例如定性研究與導入外部專家。<br>請問問自己：</p><ul><li>你的產品核心價值是什麼？如果你還沒有答案，請從你的願景尋找靈感。</li><li>如果要以產品的價值為中心來進行設計，那麼你的產品功能和過程會有什麼不同？</li><li>該產品可能產生什麼樣的態度轉變或是行為改變？這些改變是否符合你的核心價值觀？</li><li>什麼可以讓你直接作為衡量成功的基準，而非依靠點擊數、花費時間或是每日活躍用戶數？</li><li>你如何以使用值作為標準要素並以此作為優先次序？</li><li>你如何加深對於你產品選擇的理解？是否有可利用的學術研究？</li><li>你的產品似乎「提供使用者他們想要的」嗎？可能存在哪些認知偏誤呢？</li></ul></li><li><p><strong>強化現有才華</strong><br><em>假設更多科技並非唯一解</em><br>並非所有東西都需要全面升級。在適當的條件下，人類非常有能力去實現目標、與他人聯繫、玩樂和做出許多以科技尋求幫助的事情。科技可以提供空間給這類的才華，也可以取代它並使其萎縮。在每種設計選擇中，你都可以支持自然產生才華的條件。<br>舉例來說，<a href=https://livingroomconversations.org/ target=_blank>Living Room Conversations</a>便是基於這樣的理解而被創建的，即使人們發現彼此之間相似處並相互連結，他們能更輕鬆地找到共同點與共同觀點。另一個例子則是像<a href=https://www.meetup.com/ target=_blank>MeetUp</a>的線上群組服務，鼓勵有相同興趣或同好的人親自聚會來加深聯繫。<br>請問問自己：</p><ul><li>哪些內在能力或是資源會讓人們感覺良好？科技如何在不影響人們生活的情況下強化這些能力？</li><li>對於你作為產品團隊所選擇的價值觀（像是聯繫、社群、機會、或理解），你可以在現實社會中的哪裡找到靈感？</li><li>科技如何協助我們克服社會上的最大分裂（不平等、兩極分化等）？</li></ul></li><li><p><strong>考慮到所有對象（Make the Invisible Visceral）</strong><br><em>而非假設危害是極端案例</em><br>理想情況下，你的組織應該了解產品所造成的危害且完美地激勵去降低危害。在實際的情況中，這些危害是複雜、不斷改變且難以理解的。因此．在產品團隊與使用者之間建立內在、同理的連結非常重要。<br>雖然當今的許多最佳作法都以角色、焦點小組（Focus group）或「待辦事項」來吸引使用者，但人道科技需要你將使用者經驗的痛苦內化，就像是你自己的痛苦一樣。設想以下情況：</p><ul><li>你的另一半必須參加你所設計飛機的第一次飛行。</li><li>由於你設計的演算法推薦的視頻，你的母親會忽略公共衛生建議。</li><li>你的中學生孩子是社交軟體上欺淩的對象。
這種心態將能驅動更深刻的理解和謹慎。你的決策者和產品團隊必須共有一種心態－－你的工作會影響到許多人：使用者、他們周圍的人（朋友、家人、同事&mldr;）、不同的社會經濟人口（年齡、收入水準、殘疾、文化&mldr;）等。<br>請問問自己：<br></li><li>除了現有使用者之外，你的APP或服務的利益相關者是誰？</li><li>誰會因為使用你的APP或服務受到負面影響？你對他們有什麼了解？</li><li>你如何為在決策過程中服務的社群具有直接經驗的人提供權力？</li><li>如果你的解決方案是全球性的，你如何了解其他國家/地區使用者經驗的差異？</li><li>你可以導入哪些外部專業知識來說明你解決所選的問題空間？</li></ul></li><li><p><strong>開啟聰明的選項</strong><br><em>而非假設越多選擇永遠越好</em><br>隨著這個世界變得越加地複雜和不可預測，我們在理解新興現實和作出有意義選擇的能力很快會變得不堪負荷。作為一名科技人，你可以幫助人們用明智、深思熟慮、符合他們價值觀且與他們所處的脆弱社會和環境系統保持一致性的方式去做出選擇。<br>例如，在呈現新的資訊時，適當的框架可以幫助人們做出正確決策。相同的內容搭配適當的上下文將成為更有用的資訊。「聽說 COVID-19 的死亡率為 1%」 對你可能沒什麼意義。但是，「聽說 COVID-19 比流感致命幾倍」，可以讓任何人立即瞭解他們所需要知道的相關資訊。當人們以直觀的方式獲得資訊時，他們就被賦予做出更明智選擇的能力。<br>請問問自己：</p><ul><li>你為使用者提供了哪些選擇？你使用什麼樣的框架？不同的框架又會如何引導使用者做出不同的選擇？</li><li>如何以能夠促進社會團結的方式提供資訊？</li><li>我們如何幫助人們在照顧自己和保持知情之間取得平衡？</li><li>我們如何幫助人們有效地找到他們所需要的支援？</li></ul></li><li><p><strong>培養正念</strong><br><em>而非奪取專注</em><br>在一個APP不停地奪取我們注意的世界，我們的專注力正在受到攻擊。正念能以一種平靜且平衡的方式去意識我們腦海、身體和周遭發生的事情。正念使我們能夠有計畫性地行動，避免總是基於恐懼與匱乏的心而讓生活產生一系列自動的行為與反應。但像其他的能力一樣，正念是可以開發的。你可以幫助使用者重新獲得且提升他們的能力，而非爭先恐後地想要贏得更多的專注。<br>舉例來說，信件APP可以預設關閉收到郵件時的通知提示與音效，讓使用者選擇是否開啟。另一個例子是Apple Watch的Breathe APP．幫助使用者花時間專注在自己的呼吸。<br>請問問自己：</p><ul><li>科技如何幫助提升專注、清醒和鎮定的能力？</li><li>科技如何培養代理和共同意識？</li><li>你何時會為了產品的利益而非使用者的利益去奪取使用者的注意？</li></ul></li><li><p><strong>將成長與責任結合</strong><br><em>而非單純地最大化成長</em><br>當今的科技對使用它的人類越加的不對稱。機器學習（<a href=https://en.wikipedia.org/wiki/Machine_learning target=_blank>Machine learning</a>）、微目標定位（<a href=https://en.wikipedia.org/wiki/Microtargeting target=_blank>Micro-targeting</a>）、推薦引擎、深偉（<a href=https://zh.wikipedia.org/wiki/Deepfake target=_blank>Deepfake</a>）都是加大造成傷害機會的科技技術，特別是在傷害規模上更是巨大。為緩和這類情況，你可以多花時間瞭解科技在你的產品中對於認知的脆弱、社會、經濟和生態系統、產品可能造成的危害以及減輕這些危害的方法。<br>例如，最初只用於成人的產品無法避免地會隨著兒童成長而暴露於兒童的生活中。原本用於娛樂的平台也可能成為假資訊的目標；在工業化國家中最讓人受益的產品也可能在第三世界國家中會造成危害。當你的產品首次發表時，這些問題感覺離你很遙遠，但當產品使用者人數到達數以百萬計時，這就成為了一種保證。<br>即便是「好」的事情，如果做到極端也會有意想不到的負面後果。乍看之下「讚（Like）」似乎是個判斷使用者喜好的偉大信號。但在規模上，它最終造成了同溫層（Filter bubbles）和共享真相的碎片。<br>請問問自己：</p><ul><li>你如何評估危害的規模？哪些系統和流程能幫助你了解產品對使用者及更大的社會、經濟和生態系統的影響（例如，廣泛的對利益相關者測試產品)？</li><li>A/B測試通常很有說服力，因為它為產品決策者提供了快速的回饋。你是否能找到類似的解決方案來追蹤創建危害的規模？</li><li>如果你是使用者生成內容的平臺，如何避免以前平臺導致廣泛造謠和其他有毒內容的錯誤？</li><li>如果你非常成功地創造了你意圖創造的價值，那麼它附帶的失敗模式是什麼？你能如何防範？你要怎麼找出你可能錯過的？</li><li>在《芝麻街》每一集的結尾，主持人Elmo會鼓勵孩子們站起來跳舞，這樣孩子就不會坐著繼續看下一集了。你要如何提供提供類似的機制，停止隊列並讓使用者不過度使用你的產品，進而損害你意圖創造的價值？</li></ul></li></ul></main><footer class="footer text-center"><p class=text-muted><small>Designed by EstherJ <span class=mx-2>|</span> Copyright © 2023</small></p></footer><script src=/js/feather.min.js></script><script>feather.replace()</script><script src=/js/jquery-3.5.1.min.js></script><script src=/js/jquery.fancybox.min.js></script></body></html>